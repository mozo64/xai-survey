{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install jupyter openpyxl seaborn matplotlib\n",
    "# ! pip install -U sentence-transformers\n",
    "# ! pip3 install alibi scikit-learn-extra\n",
    "! pip3 install wordcloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(f\"UTC now= '{datetime.datetime.utcnow().isoformat().split('.')[0]}'\")\n",
    "\n",
    "print(f'Virtualenv used: {sys.executable}')\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn import tree\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _save_pickle(df, outfile, results_folder):\n",
    "  if results_folder:\n",
    "    results_folder_local = f\"{str(Path('~').expanduser().resolve())}/{results_folder}\"\n",
    "    # results_folder_local = results_folder\n",
    "  else:\n",
    "    results_folder_local = f\"{str(Path('~').expanduser().resolve())}/data\"\n",
    "  Path(results_folder_local).mkdir(parents=True, exist_ok=True)\n",
    "  fname = f\"{results_folder_local}/{outfile}.pickle\"\n",
    "  print(fname)\n",
    "  with open(fname, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "\n",
    "def get_LSA(df, column_to_ommit, how_many_dimmension):\n",
    "  svd = TruncatedSVD(how_many_dimmension) # >~ 70%\n",
    "  normalizer = Normalizer(copy=False)\n",
    "  lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "  df_edges_lsa = pd.DataFrame(lsa.fit_transform(df.loc[:, df.columns != column_to_ommit]))\n",
    "  print(f\"explained variance perc = {svd.explained_variance_ratio_.sum()*100}%\")\n",
    "\n",
    "  df_edges_lsa = pd.concat([df['article_which_cities'], df_edges_lsa], axis=1, join=\"inner\")\n",
    "  df_edges_lsa['cluster_kmeans'] = -1\n",
    "  return df_edges_lsa\n",
    "\n",
    "\n",
    "def k_means(df, column_to_ommit, how_many_clusters):\n",
    "  kmeans = KMeans(n_clusters=how_many_clusters, random_state=2022).fit(df.loc[:, (df.columns != column_to_ommit) & (df.columns != 'cluster_kmeans')])\n",
    "  # kmeans.labels_\n",
    "  # print(pd.DataFrame(kmeans.cluster_centers_).reset_index())\n",
    "  # print(pd.DataFrame(kmeans.cluster_centers_).reset_index()['index'])\n",
    "  df['cluster_kmeans'] = kmeans.labels_\n",
    "  # df_only_one_hots = df.loc[:, (df.columns != 'article_which_cities') & (df.columns != 'cluster_kmeans')]\n",
    "  # df[['article_which_cities', 'cluster_kmeans']]\n",
    "  return df\n",
    "\n",
    "\n",
    "def get_TSNE_and_PCA_embeddings(df_edges, column_to_ommit):\n",
    "  df_edges_independent_vars = df_edges.loc[:, (df_edges.columns != column_to_ommit) & (df_edges.columns != 'cluster_kmeans')]\n",
    "\n",
    "  df_tsne = pd.DataFrame(TSNE(n_components=2).fit_transform(df_edges_independent_vars))\n",
    "  df_tsne['cluster'] = df_edges['cluster_kmeans']\n",
    "  df_tsne.columns = ['x1', 'x2', 'cluster']\n",
    "  df_tsne['article_which_cities'] = df_edges['article_which_cities']\n",
    "\n",
    "  df_pca = pd.DataFrame(PCA(n_components=2).fit_transform(df_edges_independent_vars))\n",
    "  df_pca['cluster'] = df_edges['cluster_kmeans']\n",
    "  df_pca.columns = ['x1', 'x2', 'cluster']\n",
    "  df_pca['article_which_cities'] = df_edges['article_which_cities']\n",
    "\n",
    "  scaler = MinMaxScaler()\n",
    "  df_tsne[['x1', 'x2']] = scaler.fit_transform(df_tsne[['x1', 'x2']])\n",
    "  df_pca[['x1', 'x2']] = scaler.fit_transform(df_pca[['x1', 'x2']])\n",
    "\n",
    "  return df_tsne, df_pca\n",
    "\n",
    "\n",
    "def wrap_by_word(s, n):\n",
    "  '''returns a string where \\\\n is inserted between every n words'''\n",
    "  a = s.split()\n",
    "  ret = ''\n",
    "  for i in range(0, len(a), n):\n",
    "    ret += ' '.join(a[i:i+n]) + '\\n'\n",
    "\n",
    "  return ret\n",
    "\n",
    "# x = wrap_by_word('There is a dog and fox fighting in the park and there is an apple falling down.', 4)\n",
    "# print(x)\n",
    "def get_article_info(df_with_article_which_cities_column, column):\n",
    "  df_nodes_cp = df_nodes.copy()\n",
    "  df_nodes_cp['article_which_cities'] = df_nodes_cp['ID'].apply(lambda x: f\"{x:02d}\")\n",
    "  df_merged = df_with_article_which_cities_column.merge(df_nodes_cp, on='article_which_cities', how='left')\n",
    "\n",
    "  return df_merged['article_which_cities'] + \" (\" + df_merged['Year'].apply(lambda x: str(x)) + \") \" + \": \\n\" + df_merged[column].apply(lambda x: wrap_by_word(x, 3))\n",
    "\n",
    "# get_article_info(df_tsne_lsa, column='Title')\n",
    "\n",
    "def label_point(x, y, val, ax, factor):\n",
    "  a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "  for i, point in a.iterrows():\n",
    "    ax.text(point['x'] + 1*factor, point['y'] - 10*factor, str(point['val']))\n",
    "\n",
    "\n",
    "def visualise_clusters(df_2d_embedding, factor=1/200):\n",
    "  _fig, _ax = plt.subplots(1, 1, figsize=(12*2,6*2))\n",
    "  sns.scatterplot(data=df_2d_embedding, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, s=120, palette=\"deep\", ax=_ax)\n",
    "  label_point(df_2d_embedding['x1'], df_2d_embedding['x2'], get_article_info(df_2d_embedding, column='Title'), _ax, factor)\n",
    "  # display(_fig)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_nodes = pd.read_excel('/media/mmozolewski/m.mozolewski@gma/Documents/Doktorat/Parisa/xai-survey/RC6 nodes info(Abstract).xlsx', sheet_name=0)\n",
    "# df_edges = pd.read_excel('/media/mmozolewski/m.mozolewski@gma/Documents/Doktorat/Parisa/xai-survey/Data.xlsx', sheet_name=0)\n",
    "df_nodes = pd.read_excel('notebooks/xai-survey/RC6 nodes info(Abstract).xlsx', sheet_name=0)\n",
    "df_edges = pd.read_excel('notebooks/xai-survey/Data.xlsx', sheet_name=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nodes['Title_and_Abstract'] = df_nodes['Title'] + ' ' + df_nodes['Abstract']\n",
    "df_nodes[['ID', 'Title', 'Abstract', 'CitationCount', 'RepetitionCount']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nodes.loc[df_nodes['Abstract'].isna(), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges.loc[(df_edges['node 1']==36) | (df_edges['node 2']==36), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(df_edges['link type'].dtype)\n",
    "# df_edges.loc[32, 'link type'][0]\n",
    "# ast.literal_eval(df_edges.loc[32, 'link type'])\n",
    "df_edges['link type'] = df_edges['link type'].apply(lambda x: \"['unknown']\" if x == \"[]\" else x)\n",
    "df_edges['link type'] = df_edges['link type'].apply(lambda x: ast.literal_eval(x))\n",
    "df_edges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plan :\n",
    "# 4 relacje\n",
    "# 50 artów\n",
    "#\n",
    "# id | is_methodology_01 | is_result_01 | is_result_01 |\n",
    "# 00       true                false\n",
    "\n",
    "# Opcja: SVD (LSA) -> jak PCA, TF-IDF\n",
    "# Normalizacja\n",
    "# k-means\n",
    "# KnAC (objaśnienia na abstraktach)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_flatten = []\n",
    "for index, row in df_edges.iterrows():\n",
    "  for link_type in row['link type']:\n",
    "    df_edges_flatten.append((f\"{row['node 1']:02d}\", f\"{row['node 2']:02d}_{link_type}\", row['node 1'], row['node 2'], link_type))\n",
    "df_edges_flatten = pd.DataFrame(df_edges_flatten)\n",
    "df_edges_flatten.sort_values(by=[2, 3, 4], inplace=True)\n",
    "df_edges_flatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd.pivot_table(df_edges_flatten, index=0, values=2, columns=1, aggfunc='-'.join)\n",
    "df_edges_flatten_one_hot = pd.get_dummies(df_edges_flatten[1])\n",
    "df_edges_flatten_one_hot = pd.concat([df_edges_flatten, df_edges_flatten_one_hot], axis=1, join=\"inner\")\n",
    "df_edges_flatten_one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_one_hot = df_edges_flatten_one_hot.groupby(0).agg(lambda x: x.sum()).reset_index()\n",
    "df_edges_one_hot.rename(columns={0: \"article_which_cities\"}, inplace=True)\n",
    "del df_edges_one_hot[1]\n",
    "del df_edges_one_hot[2]\n",
    "del df_edges_one_hot[3]\n",
    "del df_edges_one_hot[4]\n",
    "df_edges_one_hot['cluster_kmeans'] = -1\n",
    "df_edges_one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSA features on One-HOT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_lsa = get_LSA(df_edges_one_hot, 'article_which_cities', 12)\n",
    "df_edges_lsa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence-BERT embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_bert = pd.DataFrame(model.encode(df_nodes['Abstract'].tolist()))\n",
    "df_edges_bert = pd.concat([df_nodes[['ID']], df_edges_bert], axis=1, join=\"inner\").rename(columns={'ID':'article_which_cities'})\n",
    "df_edges_bert['article_which_cities'] = df_edges_bert['article_which_cities'].apply(lambda x: f\"{x:02d}\")\n",
    "df_edges_bert.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_bert = pd.merge(df_edges_one_hot['article_which_cities'], df_edges_bert, left_on='article_which_cities', right_on='article_which_cities')\n",
    "df_edges_bert['cluster_kmeans'] = -1\n",
    "df_edges_bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSA features on Sentence-BERT embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_bert_lsa = get_LSA(df_edges_bert, 'article_which_cities', 13)\n",
    "df_edges_bert_lsa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SpaCy embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "# from alibi.utils.download import spacy_model\n",
    "\n",
    "model_spacy = 'en_core_web_lg'\n",
    "# spacy_model(model=model_spacy)\n",
    "spacy_nlp = spacy.load(model_spacy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_spacy = pd.DataFrame([doc.vector for doc in spacy_nlp.pipe([str(x)  for x in df_nodes['Title_and_Abstract'].tolist()])])\n",
    "df_edges_spacy = pd.concat([df_nodes[['ID']], df_edges_spacy], axis=1, join=\"inner\").rename(columns={'ID':'article_which_cities'})\n",
    "df_edges_spacy['article_which_cities'] = df_edges_spacy['article_which_cities'].apply(lambda x: f\"{x:02d}\")\n",
    "df_edges_spacy.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_spacy = pd.merge(df_edges_one_hot['article_which_cities'], df_edges_spacy, left_on='article_which_cities', right_on='article_which_cities')\n",
    "df_edges_spacy['cluster_kmeans'] = -1\n",
    "df_edges_spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSA for SpaCy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_spacy_lsa = get_LSA(df_edges_spacy, 'article_which_cities', 11)\n",
    "df_edges_spacy_lsa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-means clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_one_hot = k_means(df_edges_one_hot, 'article_which_cities', 3)\n",
    "df_edges_lsa = k_means(df_edges_lsa, 'article_which_cities', 3)\n",
    "df_edges_bert = k_means(df_edges_bert, 'article_which_cities', 3)\n",
    "df_edges_bert_lsa = k_means(df_edges_bert_lsa, 'article_which_cities', 3)\n",
    "df_edges_spacy_lsa = k_means(df_edges_spacy_lsa, 'article_which_cities', 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tsne_one_hots, df_pca_one_hots = get_TSNE_and_PCA_embeddings(df_edges_one_hot, 'article_which_cities')\n",
    "df_tsne_lsa, df_pca_lsa = get_TSNE_and_PCA_embeddings(df_edges_lsa, 'article_which_cities')\n",
    "df_tsne_bert, df_pca_bert = get_TSNE_and_PCA_embeddings(df_edges_bert, 'article_which_cities')\n",
    "df_tsne_bert_lsa, df_pca_bert_lsa = get_TSNE_and_PCA_embeddings(df_edges_bert_lsa, 'article_which_cities')\n",
    "df_tsne_spacy_lsa, df_pca_spacy_lsa = get_TSNE_and_PCA_embeddings(df_edges_spacy_lsa, 'article_which_cities')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# _save_pandas_pickle(df_tsne_one_hots, 'df_tsne_one_hots', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_pca_one_hots, 'df_pca_one_hots', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_tsne_lsa, 'df_tsne_lsa', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_pca_lsa, 'df_pca_lsa', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_tsne_bert, 'df_tsne_bert', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_pca_bert, 'df_pca_bert', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_tsne_bert_lsa, 'df_tsne_bert_lsa', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_pca_bert_lsa, 'df_pca_bert_lsa', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_tsne_spacy_lsa, 'df_pca_bert_lsa', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_pca_spacy_lsa, 'df_pca_bert_lsa', \"notebooks/xai-survey/clusters-embeddings\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12*2,6*2))\n",
    "sns.scatterplot(data=df_tsne_one_hots, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[0,0])\n",
    "ax[0,0].set_title('One-Hot - Visualized on TSNE 2D')\n",
    "sns.scatterplot(data=df_tsne_lsa, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[0,1])\n",
    "ax[0,1].set_title('LSA - Visualized on TSNE 2D')\n",
    "# sns.scatterplot(data=df_tsne_bert, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[0,2])\n",
    "# ax[0,2].set_title('** BERT - Visualized on TSNE 2D')\n",
    "\n",
    "sns.scatterplot(data=df_pca_one_hots, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[1,0])\n",
    "ax[1,0].set_title('One-Hot - Visualized on PCA 2D')\n",
    "sns.scatterplot(data=df_pca_lsa, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[1,1])\n",
    "ax[1,1].set_title('LSA - Visualized on PCA 2D')\n",
    "# sns.scatterplot(data=df_pca_bert, x='x1', y='x2', hue='cluster', style='cluster', legend=\"full\", alpha=0.9, palette=\"deep\", s=100, ax=ax[1,2])\n",
    "# ax[1,2].set_title('** BERT - Visualized on PCA 2D')\n",
    "\n",
    "fig.suptitle('Clustering result: citations data (One-Hot, LSA) \\n (visualized using TSNE2D vs. PCA2D)') #and abstracts (BERT)\n",
    "# display(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### some articles, like 20 does not cite any other article, so they are not on this graph ###\n",
    "visualise_clusters(df_tsne_lsa)\n",
    "# visualise_clusters(df_pca_lsa)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## clustering on BERT emmbedings - not good:\n",
    "# visualise_clusters(df_tsne_bert)\n",
    "visualise_clusters(df_tsne_bert_lsa)\n",
    "# visualise_clusters(df_pca_bert)\n",
    "# visualise_clusters(df_pca_bert_lsa)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualise_clusters(df_tsne_spacy_lsa)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering on citation + abstract\n",
    "## clustering on both citation data and BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_bert_lsa_and_lsa = pd.concat([df_edges_bert_lsa, df_edges_lsa.loc[:, (df_edges_lsa.columns != 'article_which_cities') & (df_edges_lsa.columns != 'cluster_kmeans')]], axis=1)\n",
    "df_edges_bert_lsa_and_lsa = k_means(df_edges_bert_lsa_and_lsa, 'article_which_cities', 7)\n",
    "df_edges_bert_lsa_and_lsa_tsne, df_edges_bert_lsa_and_lsa_pca = get_TSNE_and_PCA_embeddings(df_edges_bert_lsa_and_lsa, 'article_which_cities')\n",
    "# _save_pandas_pickle(df_edges_bert_lsa_and_lsa_tsne, 'df_edges_bert_lsa_and_lsa_tsne', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_edges_bert_lsa_and_lsa_pca, 'df_edges_bert_lsa_and_lsa_pca', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "\n",
    "visualise_clusters(df_edges_bert_lsa_and_lsa_tsne)\n",
    "# df_edges_bert_lsa_and_lsa_tsne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## clustering on both citation data and spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_edges_spacy_lsa_and_lsa = pd.concat([df_edges_spacy_lsa, df_edges_lsa.loc[:, (df_edges_lsa.columns != 'article_which_cities') & (df_edges_lsa.columns != 'cluster_kmeans')]], axis=1)\n",
    "df_edges_spacy_lsa_and_lsa = k_means(df_edges_spacy_lsa_and_lsa, 'article_which_cities', 7)\n",
    "df_edges_spacy_lsa_and_lsa_tsne, df_edges_spacy_lsa_and_lsa_pca = get_TSNE_and_PCA_embeddings(df_edges_spacy_lsa_and_lsa, 'article_which_cities')\n",
    "# _save_pandas_pickle(df_edges_spacy_lsa_and_lsa_tsne, 'df_edges_spacy_lsa_and_lsa_tsne', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "# _save_pandas_pickle(df_edges_spacy_lsa_and_lsa_pca, 'df_edges_spacy_lsa_and_lsa_pca', \"notebooks/xai-survey/clusters-embeddings\")\n",
    "\n",
    "visualise_clusters(df_edges_spacy_lsa_and_lsa_tsne)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO :\n",
    "# Zamiast BERT - TF-IDF, W2V\n",
    "# clamp -> objaśnie klustw\n",
    "# expert clusters from Parisa  -> knAC\n",
    "# inxai -> dodac NLU, metryki"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## explain clusters on citations with abstracts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_cluster_col(df_nodes, df_with_cluster_kmeans_column):\n",
    "  df_nodes['ID-str'] = df_nodes['ID'].apply(lambda x: f\"{x:02d}\")\n",
    "  df_edges_for_xai = pd.merge(df_with_cluster_kmeans_column.loc[:, ['article_which_cities', 'cluster_kmeans']], df_nodes[['ID-str', 'Title', 'Abstract']], left_on='article_which_cities', right_on='ID-str')[['article_which_cities', 'cluster_kmeans', 'Title', 'Abstract']]\n",
    "  df_edges_for_xai['Title_and_Abstract'] = df_edges_for_xai['Title'] + ' ' + df_edges_for_xai['Abstract']\n",
    "  return df_edges_for_xai\n",
    "\n",
    "df_edges_for_xai = add_cluster_col(df_nodes, df_edges_lsa)\n",
    "df_edges_for_xai"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_stopwords = spacy_nlp.Defaults.stop_words\n",
    "all_stopwords.update(['et', 'al', 'approach', 'model', 'method', 'explanation']) ## TODO get better list from bigger corpus of abstracts\n",
    "'method' in all_stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###  TODO\n",
    "# mniej klastrow\n",
    "# decision tree classfier\n",
    "# potem odwrocic TF-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## TODO - use Cross Validation\n",
    "train, test, train_labels, test_labels = train_test_split(\n",
    "  df_edges_for_xai['Abstract'], df_edges_for_xai['cluster_kmeans'], test_size=.3) # , random_state=202205\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=20, stop_words=all_stopwords, min_df=2, max_df=.2, ngram_range=(1,2)) # CountVectorizer(max_features=100, stop_words=all_stopwords) #\n",
    "vectorizer.fit(train)\n",
    "\n",
    "clf = DecisionTreeClassifier() # xgb.XGBClassifier(use_label_encoder=True) # LogisticRegression(solver='liblinear') #\n",
    "clf.fit(vectorizer.transform(train), train_labels)\n",
    "predict_fn = lambda x: clf.predict(vectorizer.transform(x))\n",
    "\n",
    "preds_train = predict_fn(train)\n",
    "preds_test = predict_fn(test)\n",
    "print('Train accuracy', accuracy_score(train_labels, preds_train))\n",
    "print('Test accuracy', accuracy_score(test_labels, preds_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(preds_train)\n",
    "print(preds_test)\n",
    "# vectorizer.transform([\"The problem of attributing the prediction of a deep network to its input features\"])\n",
    "# predict_fn([\"The problem of attributing the prediction of a deep network to its input features\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response = vectorizer.fit_transform(df_edges_for_xai['Abstract'])\n",
    "df_edges_for_xai_vectors = pd.DataFrame(response.toarray(), columns=vectorizer.get_feature_names())\n",
    "print(vectorizer.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# _save_pickle(clf, 'clf_DecisionTreeClassifier', \"notebooks/xai-survey/clusters-embeddings\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualization\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "vis = tree.plot_tree(clf, feature_names = vectorizer.get_feature_names(), class_names = [\"0\", \"1\", \"2\"], max_depth=5, fontsize=9, proportion=True, filled=True, rounded=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for cluster in [0, 1, 2]:\n",
    "  print (cluster)\n",
    "  # Start with one review:\n",
    "  text = word_tokenize(\" \".join(df_edges_for_xai.loc[df_edges_for_xai['cluster_kmeans']==cluster, 'Abstract'].tolist()))\n",
    "  text = \" \".join([w for w in text if not w.lower() in all_stopwords])\n",
    "\n",
    "  # Create and generate a word cloud image:\n",
    "  wordcloud = WordCloud().generate(text)\n",
    "\n",
    "  # Display the generated image:\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## TODO\n",
    "# - Use expert knowledge??\n",
    "# - Use citations : cluster 1 == cities_art_12\n",
    "#   - common words in abstract for cluster (~ TFID)\n",
    "\n",
    "# Wizualizacja - czym różnią się clustry:\n",
    "# - word cloud dla clustra + polaczenia między clustrami - czym się różnią\n",
    "\n",
    "# Counterfactual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}