
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.


@article{xaiclust2021,
author = {Lötsch, Jörn and Malkusch, Sebastian},
title = {Interpretation of cluster structures in pain-related phenotype data using explainable artificial intelligence (XAI)},
journal = {European Journal of Pain},
volume = {25},
number = {2},
pages = {442-465},
doi = {https://doi.org/10.1002/ejp.1683},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ejp.1683},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejp.1683},
abstract = {Abstract Background In pain research and clinics, it is common practice to subgroup subjects according to shared pain characteristics. This is often achieved by computer-aided clustering. In response to a recent EU recommendation that computer-aided decision making should be transparent, we propose an approach that uses machine learning to provide (1) an understandable interpretation of a cluster structure to (2) enable a transparent decision process about why a person concerned is placed in a particular cluster. Methods Comprehensibility was achieved by transforming the interpretation problem into a classification problem: A sub-symbolic algorithm was used to estimate the importance of each pain measure for cluster assignment, followed by an item categorization technique to select the relevant variables. Subsequently, a symbolic algorithm as explainable artificial intelligence (XAI) provided understandable rules of cluster assignment. The approach was tested using 100-fold cross-validation. Results The importance of the variables of the data set (6 pain-related characteristics of 82 healthy subjects) changed with the clustering scenarios. The highest median accuracy was achieved by sub-symbolic classifiers. A generalized post-hoc interpretation of clustering strategies of the model led to a loss of median accuracy. XAI models were able to interpret the cluster structure almost as correctly, but with a slight loss of accuracy. Conclusions Assessing the variables importance in clustering is important for understanding any cluster structure. XAI models are able to provide a human-understandable interpretation of the cluster structure. Model selection must be adapted individually to the clustering problem. The advantage of comprehensibility comes at an expense of accuracy.},
year = {2021}
}

@inproceedings{anchor,
  title={Anchors: High-Precision Model-Agnostic Explanations},
  author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  booktitle={AAAI},
  year={2018}
}

@InProceedings{lux2021iccs,
  author="Bobek, Szymon
  and Nalepa, Grzegorz J.",
  editor="Paszynski, Maciej
  and Kranzlm{\"u}ller, Dieter
  and Krzhizhanovskaya, Valeria V.
  and Dongarra, Jack J.
  and Sloot, Peter M. A.",
  title="Introducing Uncertainty into Explainable AI Methods",
  booktitle="Computational Science -- ICCS 2021",
  year="2021",
  publisher="Springer International Publishing",
  address="Cham",
  pages="444--457",
  isbn="978-3-030-77980-1"
}

@inproceedings{lime,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {“{W}hy Should I Trust You?”: Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {interpretable machine learning, explaining machine learning, interpretability, black box classifier},
location = {San Francisco, California, USA},
series = {KDD ’16}
}
  

@article{tsne,
  added-at = {2012-01-16T13:25:40.000+0100},
  author = {Hinton, Geoffrey and Roweis, Sam},
  biburl = {https://www.bibsonomy.org/bibtex/2a0d72c90aa3348858a647e7603ad7323/gromgull},
  description = {Stochastic Neighbor Embedding | Mendeley},
  editor = {S Becker, S Thrun and Obermayer, KEditors},
  interhash = {e29fa9b96e5445390b32830bc42e69ca},
  intrahash = {a0d72c90aa3348858a647e7603ad7323},
  journal = {Advances in neural information processing systems},
  keywords = {dimensionality-reduction embedding machine-learning visualisation},
  pages = {833--840},
  publisher = {Citeseer},
  timestamp = {2012-01-16T13:25:40.000+0100},
  title = {Stochastic Neighbor Embedding},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.7959&rep=rep1&type=pdf},
  volume = 15,
  year = 2003
}




@article{dasgupta2020explainable,
  title={Explainable $k$-Means and $k$-Medians Clustering},
  author={Dasgupta, Sanjoy and Frost, Nave and Moshkovitz, Michal and Rashtchian, Cyrus},
  journal={arXiv preprint arXiv:2002.12538},
  year={2020}
}


@article{frost2020exkmc,
  title={ExKMC: Expanding Explainable $k$-Means Clustering},
  author={Frost, Nave and Moshkovitz, Michal and Rashtchian, Cyrus},
  journal={arXiv preprint arXiv:2006.02399},
  year={2020}
}

@article{knac2021arxiv,
  author    = {Szymon Bobek and
               Michal Kuk and
               Jakub Brzegowski and
               Edyta Brzychczy and
               Grzegorz J. Nalepa},
  title     = {KnAC: an approach for enhancing cluster analysis with background knowledge
               and explanations},
  journal   = {CoRR},
  volume    = {abs/2112.08759},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.08759},
  eprinttype = {arXiv},
  eprint    = {2112.08759},
  timestamp = {Mon, 03 Jan 2022 15:45:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-08759.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{sandler2019mobilenetv2,
      title={MobileNetV2: Inverted Residuals and Linear Bottlenecks},
      author={Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
      year={2019},
      eprint={1801.04381},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


%%%%%%%%%%%%%%%%%%

@inproceedings{pmlr-v139-laber21a,
  title = 	 {On the price of explainability for some clustering problems},
  author =       {Laber, Eduardo S and Murtinho, Lucas},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5915--5925},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/laber21a/laber21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/laber21a.html},
  abstract = 	 {The price of explainability for a clustering task can be defined as the unavoidable loss, in terms of the objective function, if we force the final partition to be explainable. Here, we study this price for the following clustering problems: $k$-means, $k$-medians, $k$-centers and maximum-spacing. We provide upper and lower bounds for a natural model where explainability is achieved via decision trees. For the $k$-means and $k$-medians problems our upper bounds improve those obtained by [Dasgupta et. al, ICML 20] for low dimensions. Another contribution is a simple and efficient algorithm for building explainable clusterings for the $k$-means problem. We provide empirical evidence that its performance is better than the current state of the art for decision-tree based explainable clustering.}
}


@inproceedings{hendricks2016generating,
  title={Generating visual explanations},
  author={Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={3--19},
  year={2016},
  organization={Springer}
}

@article{10.1145/3340960,
    author = {Bae, Juhee and Helldin, Tove and Riveiro, Maria and Nowaczyk, S\l{}awomir and Bouguelia, Mohamed-Rafik and Falkman, G\"{o}ran},
    title = {Interactive Clustering: A Comprehensive Review},
    year = {2020},
    issue_date = {January 2021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {53},
    number = {1},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3340960},
    doi = {10.1145/3340960},
    abstract = {In this survey, 105 papers related to interactive clustering were reviewed according to seven perspectives: (1) on what level is the interaction happening, (2) which interactive operations are involved, (3) how user feedback is incorporated, (4) how interactive clustering is evaluated, (5) which data and (6) which clustering methods have been used, and (7) what outlined challenges there are. This article serves as a comprehensive overview of the field and outlines the state of the art within the area as well as identifies challenges and future research needs.},
    journal = {ACM Comput. Surv.},
    month = {feb},
    articleno = {1},
    numpages = {39},
    keywords = {Clustering, evaluation, feedback, interactive, interaction, user}
}
